{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries and scientific computing packages\n",
    "import pickle  # For loading/saving Python objects in binary format\n",
    "import numpy as np  # Fundamental package for numerical computations with arrays\n",
    "import pandas as pd  # Powerful data manipulation and analysis library\n",
    "import matplotlib.pyplot as plt  # Plotting library for creating static, animated, and interactive visualizations\n",
    "import seaborn as sns  # Statistical data visualization built on matplotlib\n",
    "import os  # Import os module for file and directory path operations\n",
    "from glob import glob  # Import glob to find files matching patterns\n",
    "import chardet  # Import chardet to detect file encoding automatically\n",
    "import seaborn as sns # Import seaborn for advanced and easier data visualization, especially heatmaps\n",
    "\n",
    "# Import various utilities from scikit-learn for model selection, preprocessing, feature selection, metrics, and base classes\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV  # GroupKFold for grouped cross-validation, GridSearchCV for hyperparameter tuning\n",
    "from sklearn.preprocessing import StandardScaler  # Standardizes features by removing the mean and scaling to unit variance\n",
    "from sklearn.impute import SimpleImputer  # Handles missing values by imputing (here, with mean)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif  # SelectKBest selects top k features based on ANOVA F-value\n",
    "from sklearn.metrics import (classification_report, accuracy_score, confusion_matrix, roc_curve, auc,\n",
    "                             f1_score, precision_score, recall_score, hamming_loss, roc_auc_score)  # Various classification evaluation metrics\n",
    "from sklearn.base import BaseEstimator, TransformerMixin  # Base classes for building custom transformers and estimators\n",
    "from sklearn.utils import shuffle  # Utility to shuffle arrays or sparse matrices in a consistent way\n",
    "\n",
    "# Imbalanced-learn (imblearn) imports for handling imbalanced datasets via over- and under-sampling\n",
    "from imblearn.over_sampling import SMOTENC  # SMOTE variant for categorical features\n",
    "from imblearn.under_sampling import RandomUnderSampler  # Random under-sampling to balance classes\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # Pipeline supporting imbalanced data operations\n",
    "from imblearn.combine import SMOTEENN  # Combined over- and under-sampling method\n",
    "from imblearn.over_sampling import RandomOverSampler  # Random over-sampling\n",
    "\n",
    "# CatBoost classifier for gradient boosting with categorical support\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Multiclass classifier wrapper for multilabel problems\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# SHAP for explainable AI: interpreting model predictions\n",
    "import shap\n",
    "\n",
    "# Warning control\n",
    "import warnings\n",
    "\n",
    "# Utility to compute class weights for imbalanced data\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# xarray for handling labeled multi-dimensional arrays (used for EEG data here)\n",
    "import xarray as xr\n",
    "\n",
    "# Redundant imports (CatBoostClassifier, OneVsRestClassifier, shuffle, SelectKBest) - could be cleaned up\n",
    "\n",
    "\n",
    "# Custom transformer class to drop columns with all missing values (NaNs)\n",
    "class DropAllNaNColumns(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # Converts input to DataFrame to check for columns that are all NaN\n",
    "        X_df = pd.DataFrame(X)\n",
    "        # Store boolean mask of columns that are not all NaN for use in transform\n",
    "        self.non_nan_cols_ = ~np.all(X_df.isna(), axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Convert input to DataFrame and select only columns that are not all NaN\n",
    "        X_df = pd.DataFrame(X)\n",
    "        return X_df.loc[:, self.non_nan_cols_].values\n",
    "\n",
    "\n",
    "# Wrapper class for CatBoost classifier using OneVsRest for multilabel classification\n",
    "class CatBoostOVRWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.03, depth=6, iterations=1000, **kwargs):\n",
    "        # Initialize with default CatBoost hyperparameters and additional kwargs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.depth = depth\n",
    "        self.iterations = iterations\n",
    "        self.kwargs = kwargs\n",
    "        self.model = None\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        # Returns parameters for sklearn compatibility (used in GridSearchCV)\n",
    "        return {\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'depth': self.depth,\n",
    "            'iterations': self.iterations,\n",
    "            **self.kwargs,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        # Allows setting parameters; distinguishes between main params and extra kwargs\n",
    "        for key, value in params.items():\n",
    "            if key in ['learning_rate', 'depth', 'iterations']:\n",
    "                setattr(self, key, value)\n",
    "            else:\n",
    "                self.kwargs[key] = value\n",
    "        return self\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Detect categorical features automatically (here, only 'condition' column is categorical)\n",
    "        self.cat_features = [col for col in X.columns if col == 'condition']\n",
    "\n",
    "        # Initialize CatBoostClassifier with parameters and categorical feature info\n",
    "        base_model = CatBoostClassifier(\n",
    "            learning_rate=self.learning_rate,\n",
    "            depth=self.depth,\n",
    "            iterations=self.iterations,\n",
    "            cat_features=self.cat_features,\n",
    "            **self.kwargs,\n",
    "        )\n",
    "        # Wrap with OneVsRestClassifier to support multilabel classification\n",
    "        self.model = OneVsRestClassifier(base_model)\n",
    "        # Fit model on training data\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict multilabel classes for input data\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Predict probability estimates for multilabel classes\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "\n",
    "# Function to perform feature selection for multilabel data by selecting top-k features per label and taking union\n",
    "def multi_label_select_kbest_union(X, Y, k=10):\n",
    "    n_labels = Y.shape[1]  # Number of labels (multilabel classification)\n",
    "    selected_feature_indices = set()  # Store unique selected feature indices\n",
    "\n",
    "    # For each label, perform SelectKBest feature selection and collect indices\n",
    "    for i in range(n_labels):\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "        selector.fit(X, Y[:, i])\n",
    "        indices = selector.get_support(indices=True)\n",
    "        selected_feature_indices.update(indices)\n",
    "\n",
    "    # Return sorted list of selected feature indices combining all labels\n",
    "    selected_feature_indices = sorted(list(selected_feature_indices))\n",
    "    return selected_feature_indices\n",
    "\n",
    "\n",
    "# === Load data from pickle file ===\n",
    "file_path = \"/Volumes/NOC_Drive/biomarker_data.pkl\"\n",
    "with open(file_path, \"rb\") as file:\n",
    "    hbn_data = pickle.load(file)\n",
    "\n",
    "# Extract EEG data and cohort dataframe\n",
    "eeg_data = hbn_data[\"HBN_source_space\"][\"eeg_xdata\"]\n",
    "cohort_df = hbn_data[\"HBN_source_space\"][\"cohort_df\"].copy()\n",
    "\n",
    "# Extract subject unique IDs from EEG filenames using regex\n",
    "cohort_df['subject_uid'] = cohort_df['eeg_filename'].str.extract(r'HBN-sub-(NDAR[A-Z0-9]+)')[0]\n",
    "# Extract condition (EO or EC) from filenames\n",
    "cohort_df['condition'] = cohort_df['eeg_filename'].str.extract(r'_(EO|EC)_')[0]\n",
    "\n",
    "# Define a list of selected disorders for classification\n",
    "selected_disorders = [\n",
    "    'ADHD-Combined Type',\n",
    "    'ADHD-Hyperactive/Impulsive Type',\n",
    "    'ADHD-Inattentive Type',\n",
    "    'ADHD-Other',\n",
    "    'Anxiety Disorders',\n",
    "    'ASD',\n",
    "    'Communication Disorders',\n",
    "    'Depressive Disorders',\n",
    "    'Disruptive, Impulse Control and Conduct Disorders-Other',\n",
    "    'Elimination Disorders',\n",
    "    'Healthy controls',\n",
    "    'Intellectual Disability',\n",
    "    'OCD',\n",
    "    'OCD-Other',\n",
    "    'Oppositional Defiant Disorder',\n",
    "    'SLD (Mathematics)',\n",
    "    'SLD (Reading)',\n",
    "    'SLD (Written Expression)',\n",
    "    'Tic Disorders',\n",
    "    'Trauma and Stressor Related Disorders'\n",
    "]\n",
    "\n",
    "# Calculate class counts for each disorder, filter for disorders with at least 15 samples\n",
    "class_counts = cohort_df[selected_disorders].sum()\n",
    "valid_disorders = class_counts[class_counts >= 15].index.tolist()\n",
    "if not valid_disorders:\n",
    "    raise ValueError(\"No disorders have at least 15 samples!\")\n",
    "\n",
    "# Filter cohort to include only rows with at least one valid disorder label\n",
    "df_multi = cohort_df[cohort_df[valid_disorders].sum(axis=1) >= 1].copy()\n",
    "# Extract multilabel targets matrix for valid disorders\n",
    "y = df_multi[valid_disorders].values.astype(int)\n",
    "\n",
    "# Verify that each class has enough samples (more than 10 here)\n",
    "min_class_counts = y.sum(axis=0)\n",
    "if np.any(min_class_counts <= 10):\n",
    "    raise ValueError(f\"Not enough samples in all classes. Class counts: {min_class_counts}\")\n",
    "\n",
    "# Get IDs and conditions from EEG data coordinates\n",
    "ids = eeg_data.coords['subject_uid'].values\n",
    "conditions = eeg_data.coords['condition'].values\n",
    "\n",
    "# Map (subject_uid, condition) tuple to index in EEG data for quick lookup\n",
    "index_map = {(uid, cond): i for i, (uid, cond) in enumerate(zip(ids, conditions))}\n",
    "\n",
    "# Function to map subset of dataframe rows to EEG data indices\n",
    "def map_indices(df_subset):\n",
    "    indices = []\n",
    "    for row in df_subset.itertuples():\n",
    "        idx = index_map.get((row.subject_uid, row.condition))\n",
    "        if idx is not None:\n",
    "            indices.append(idx)\n",
    "    return indices\n",
    "\n",
    "# Get indices in EEG data corresponding to filtered cohort subset\n",
    "indices = map_indices(df_multi)\n",
    "# Select EEG data matching those indices\n",
    "eeg_selected = eeg_data.isel(ID=indices)\n",
    "\n",
    "# Define frequency bands and their corresponding frequency ranges (Hz)\n",
    "frequency_combinations = [\n",
    "    ['1.0-4.0 Hz'],  # Delta band\n",
    "    ['4.0-5.1 Hz', '5.1-6.5 Hz', '6.5-8.3 Hz'],  # Theta band\n",
    "    ['8.3-10.5 Hz', '10.5-13.4 Hz'],  # Alpha band\n",
    "    ['13.4-17.0 Hz', '17.0-21.7 Hz', '21.7-27.6 Hz'],  # Beta band\n",
    "    ['27.6-35.2 Hz', '35.2-44.8 Hz']  # Gamma band\n",
    "]\n",
    "frequency_labels = ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n",
    "\n",
    "# Extract frequency coordinate values from EEG data\n",
    "freq_coords = eeg_selected.coords['frequency'].values\n",
    "combined_freq_data = []\n",
    "\n",
    "# Average frequency values within each defined band and combine them\n",
    "for band_freqs in frequency_combinations:\n",
    "    # Find indices matching frequencies in the band\n",
    "    indices_f = [i for i, f in enumerate(freq_coords) if f in band_freqs]\n",
    "    if indices_f:\n",
    "        # Average over frequency dimension for the selected band\n",
    "        avg_data = eeg_selected.isel(frequency=indices_f).mean(dim='frequency')\n",
    "        combined_freq_data.append(avg_data)\n",
    "    else:\n",
    "        raise ValueError(f\"No matching frequencies found for band: {band_freqs}\")\n",
    "\n",
    "# Concatenate averaged frequency band data into a new dimension\n",
    "combined_data = xr.concat(combined_freq_data, dim='frequency')\n",
    "# Assign frequency band labels\n",
    "combined_data = combined_data.assign_coords(frequency=frequency_labels)\n",
    "# Rearrange dimensions to desired order\n",
    "combined_data = combined_data.transpose('ID', 'source', 'frequency', 'biomarker')\n",
    "\n",
    "# Extract data shape info (samples, sources, frequencies, biomarkers)\n",
    "n_samples, n_sources, n_freqs, n_biomarkers = eeg_selected.shape\n",
    "\n",
    "# Generate feature names for all EEG features combining biomarkers, frequencies, and sources\n",
    "eeg_feature_names_all = [\n",
    "    f\"biomarker_{b}_freq_{f}_source_{s}\"\n",
    "    for s in range(n_sources)\n",
    "    for f in range(n_freqs)\n",
    "    for b in range(n_biomarkers)\n",
    "]\n",
    "\n",
    "# Flatten combined EEG data into 2D array (samples x features) for machine learning input\n",
    "X_raw = combined_data.values.reshape(combined_data.shape[0], -1)\n",
    "\n",
    "# Extract categorical condition feature and reset index for merging\n",
    "condition_cat = df_multi['condition'].astype('category').reset_index(drop=True)\n",
    "# Convert flattened EEG features into DataFrame\n",
    "X_raw_df = pd.DataFrame(X_raw)\n",
    "# Combine EEG features and categorical condition column into one DataFrame\n",
    "X_df = pd.concat([X_raw_df, condition_cat], axis=1)\n",
    "# Rename columns: numerical features named as string numbers, last column is 'condition'\n",
    "X_df.columns = list(map(str, range(X_raw.shape[1]))) + ['condition']\n",
    "\n",
    "cat_features = ['condition']  # Categorical feature column name\n",
    "\n",
    "# Initialize data preprocessing objects\n",
    "dropper = DropAllNaNColumns()  # Drop columns with all NaN values\n",
    "imputer = SimpleImputer(strategy='mean')  # Fill missing values with mean\n",
    "scaler = StandardScaler()  # Standardize features\n",
    "\n",
    "# Define parameter grid for CatBoost hyperparameter tuning via GridSearchCV\n",
    "param_grid = {\n",
    "    'depth': [4, 6],  # Tree depth\n",
    "    'learning_rate': [0.01, 0.05],  # Learning rate\n",
    "    'l2_leaf_reg': [3, 5]  # L2 regularization parameter\n",
    "}\n",
    "\n",
    "# Initialize lists to collect evaluation metrics across cross-validation folds\n",
    "outer_scores = []\n",
    "auc_scores = []\n",
    "hamming_losses = []\n",
    "subset_accuracies = []\n",
    "micro_f1s = []\n",
    "macro_f1s = []\n",
    "micro_precisions = []\n",
    "micro_recalls = []\n",
    "roc_aucs = []\n",
    "roc_curves = []\n",
    "\n",
    "# Use GroupKFold cross-validation to split data ensuring samples from the same subject don't leak across folds\n",
    "groups = df_multi['subject_uid'].values\n",
    "outer_cv = GroupKFold(n_splits=10)\n",
    "\n",
    "# Lists for storing selected features and SHAP explanations per fold\n",
    "selected_feature_indices_per_fold = []\n",
    "all_shap_feature_dfs = []\n",
    "\n",
    "# Reinitialize metric lists (some duplicates present, could be cleaned)\n",
    "outer_scores = []\n",
    "auc_scores = []\n",
    "f1_micro_scores = []\n",
    "f1_macro_scores = []\n",
    "hamming_losses = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "# Loop over folds for outer cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X_df, y[:, 0], groups=groups), 1):\n",
    "    print(f\"\\n--- Outer Fold {fold} ---\")\n",
    "\n",
    "    # Split train/test data for this fold\n",
    "    X_train = X_df.iloc[train_idx].copy()\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X_df.iloc[test_idx].copy()\n",
    "    y_test = y[test_idx]\n",
    "\n",
    "    # Separate EEG numerical features and categorical feature in train set\n",
    "    X_train_eeg = X_train.drop(columns=cat_features).values\n",
    "    X_train_cat = X_train[cat_features].reset_index(drop=True)\n",
    "\n",
    "    # Preprocessing train EEG features\n",
    "    X_train_eeg = dropper.fit_transform(X_train_eeg)  # Drop all-NaN columns\n",
    "    X_train_eeg = imputer.fit_transform(X_train_eeg)  # Impute missing values with mean\n",
    "\n",
    "    # Select top features based on multilabel feature selection union (max 1000 or 20% of features)\n",
    "    k_features = min(int(0.2 * X_train_eeg.shape[1]), 1000)\n",
    "    selected_indices = multi_label_select_kbest_union(X_train_eeg, y_train, k=k_features)\n",
    "    selected_feature_names = [eeg_feature_names_all[i] for i in selected_indices]\n",
    "    selected_feature_indices_per_fold.append(selected_indices)\n",
    "\n",
    "    # Reduce train data to selected features\n",
    "    X_train_eeg = X_train_eeg[:, selected_indices]\n",
    "    X_train_eeg = scaler.fit_transform(X_train_eeg)  # Standardize features\n",
    "\n",
    "    # Recombine EEG features and categorical feature into DataFrame\n",
    "    X_train_df = pd.DataFrame(X_train_eeg, columns=[f'feat_{i}' for i in range(X_train_eeg.shape[1])])\n",
    "    X_train_df = pd.concat([X_train_df.reset_index(drop=True), X_train_cat], axis=1)\n",
    "    for cat_col in cat_features:\n",
    "        X_train_df[cat_col] = X_train_df[cat_col].astype('category')  # Ensure categorical dtype\n",
    "\n",
    "    # --------------------\n",
    "    # ⚖️ Balanced Oversampling Per Label (to address class imbalance)\n",
    "    # --------------------\n",
    "    X_resampled_list = []\n",
    "    y_resampled_list = []\n",
    "\n",
    "    # For each label, apply random oversampling individually and expand labels accordingly\n",
    "    for i in range(y_train.shape[1]):\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        X_tmp, y_tmp = ros.fit_resample(X_train_df, y_train[:, i])\n",
    "\n",
    "        # Create multilabel target array where only current label column is filled, others zeros\n",
    "        y_tmp_full = np.zeros((X_tmp.shape[0], y_train.shape[1]))\n",
    "        y_tmp_full[:, i] = y_tmp\n",
    "\n",
    "        X_resampled_list.append(X_tmp)\n",
    "        y_resampled_list.append(y_tmp_full)\n",
    "\n",
    "    # Combine resampled data from all labels\n",
    "    X_train_balanced = pd.concat(X_resampled_list, ignore_index=True)\n",
    "    y_train_balanced = np.vstack(y_resampled_list)\n",
    "\n",
    "    # --------------------\n",
    "    # 🔧 GridSearchCV for CatBoost classifier\n",
    "    # --------------------\n",
    "    model = CatBoostOVRWrapper(iterations=500, verbose=0, cat_features=cat_features)\n",
    "\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='f1_micro', cv=3, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "    # Prepare test set features (apply same processing)\n",
    "    X_test_eeg = X_test.drop(columns=cat_features).values\n",
    "    X_test_eeg = dropper.transform(X_test_eeg)\n",
    "    X_test_eeg = imputer.transform(X_test_eeg)\n",
    "    X_test_eeg = X_test_eeg[:, selected_indices]\n",
    "    X_test_eeg = scaler.transform(X_test_eeg)\n",
    "\n",
    "    # Recombine test features and categorical feature\n",
    "    X_test_df = pd.DataFrame(X_test_eeg, columns=[f'feat_{i}' for i in range(X_test_eeg.shape[1])])\n",
    "    X_test_df = pd.concat([X_test_df.reset_index(drop=True), X_test[cat_features].reset_index(drop=True)], axis=1)\n",
    "    for cat_col in cat_features:\n",
    "        X_test_df[cat_col] = X_test_df[cat_col].astype('category')\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred = best_model.predict(X_test_df)\n",
    "    y_prob = best_model.predict_proba(X_test_df)\n",
    "\n",
    "    # Calculate various evaluation metrics for multilabel classification\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    precision_micro = precision_score(y_test, y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "    h_loss = hamming_loss(y_test, y_pred)\n",
    "    roc_auc_micro = roc_auc_score(y_test, y_prob, average='micro', multi_class='ovo')\n",
    "\n",
    "    # Append metrics for fold\n",
    "    outer_scores.append(acc)\n",
    "    f1_micro_scores.append(f1_micro)\n",
    "    f1_macro_scores.append(f1_macro)\n",
    "    precisions.append(precision_micro)\n",
    "    recalls.append(recall_micro)\n",
    "    hamming_losses.append(h_loss)\n",
    "    roc_aucs.append(roc_auc_micro)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Micro: {f1_micro:.4f}\")\n",
    "    print(f\"F1 Macro: {f1_macro:.4f}\")\n",
    "    print(f\"Precision Micro: {precision_micro:.4f}\")\n",
    "    print(f\"Recall Micro: {recall_micro:.4f}\")\n",
    "    print(f\"Hamming Loss: {h_loss:.4f}\")\n",
    "    print(f\"ROC AUC Micro: {roc_auc_micro:.4f}\")\n",
    "\n",
    "    # --------------------\n",
    "    # SHAP Explanation\n",
    "    # --------------------\n",
    "    # Use TreeExplainer for CatBoost to get SHAP values\n",
    "    explainer = shap.TreeExplainer(best_model.model.estimators_[0].get_booster())\n",
    "    shap_values = explainer.shap_values(X_test_df)\n",
    "\n",
    "    # Convert SHAP values to DataFrame with feature names\n",
    "    if isinstance(shap_values, list):\n",
    "        # If list of arrays for multilabel, stack horizontally\n",
    "        shap_values_all = np.hstack(shap_values)\n",
    "    else:\n",
    "        shap_values_all = shap_values\n",
    "\n",
    "    shap_df = pd.DataFrame(shap_values_all, columns=X_test_df.columns)\n",
    "    shap_df['subject_uid'] = df_multi.iloc[test_idx]['subject_uid'].values\n",
    "    shap_df['fold'] = fold\n",
    "    all_shap_feature_dfs.append(shap_df)\n",
    "\n",
    "# After all folds, concatenate SHAP explanations into one DataFrame for analysis\n",
    "shap_results_df = pd.concat(all_shap_feature_dfs, ignore_index=True)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save evaluation metrics to CSV ===\n",
    "\n",
    "# Create a DataFrame named metrics_df with all collected evaluation metrics from cross-validation folds\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, len(outer_scores) + 1)),  # Fold numbers from 1 up to number of folds\n",
    "    'Accuracy': outer_scores,                       # List of accuracy scores per fold\n",
    "    'AUC': auc_scores,                             # List of AUC scores per fold (area under ROC curve)\n",
    "    'F1_Micro': f1_micro_scores,                   # Micro-averaged F1 scores per fold (accounts for label imbalance)\n",
    "    'F1_Macro': f1_macro_scores,                   # Macro-averaged F1 scores per fold (treats all labels equally)\n",
    "    'Hamming_Loss': hamming_losses,                # Hamming loss per fold (fraction of labels incorrectly predicted)\n",
    "    'Precision': precisions,                        # Precision scores per fold (positive predictive value)\n",
    "    'Recall': recalls                               # Recall scores per fold (true positive rate)\n",
    "})\n",
    "\n",
    "# Define the full file path where the metrics CSV will be saved\n",
    "metrics_csv_path = \"/Users/tuanadurmayuksel/Desktop/Multi_Final/model_metrics_20com1.csv\"\n",
    "\n",
    "# Save the metrics DataFrame to a CSV file at the specified path without including the index column\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "\n",
    "# Print a confirmation message that the metrics were saved successfully\n",
    "print(f\"\\n✅ Saved metrics to {metrics_csv_path}\")\n",
    "\n",
    "\n",
    "# === Save SHAP feature importances to CSV ===\n",
    "# Concatenate all SHAP DataFrames from each fold into one combined DataFrame\n",
    "# Assign a new column 'Fold' to each DataFrame indicating which fold it belongs to (fold indices start at 1)\n",
    "shap_combined_df = pd.concat([\n",
    "    df.assign(Fold=fold_num + 1) for fold_num, df in enumerate(all_shap_feature_dfs)\n",
    "])\n",
    "\n",
    "# Define the full file path where the combined SHAP feature importances CSV will be saved\n",
    "shap_csv_path = \"/Users/tuanadurmayuksel/Desktop/Multi_Final/shap_feature_importances_20com1.csv\"\n",
    "\n",
    "# Save the combined SHAP DataFrame to a CSV file at the specified path without including the index column\n",
    "shap_combined_df.to_csv(shap_csv_path, index=False)\n",
    "\n",
    "# Print a confirmation message that the SHAP importances were saved successfully\n",
    "print(f\"✅ Saved SHAP importances to {shap_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to detect the text encoding of a given file\n",
    "def detect_encoding(file_path):\n",
    "    # Open the file in binary mode and read first 10,000 bytes for encoding detection\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read(10000))  # Use chardet to guess encoding from bytes\n",
    "    return result['encoding']  # Return the detected encoding string (e.g., 'utf-8')\n",
    "\n",
    "# Specify the directory containing all model metric CSV files\n",
    "metrics_dir = \"/Users/tuanadurmayuksel/Desktop/Multi_Final\"\n",
    "\n",
    "# Use glob to get a list of all CSV files starting with \"model_metrics_\" in the metrics directory\n",
    "metric_files = glob(os.path.join(metrics_dir, \"model_metrics_*.csv\"))\n",
    "\n",
    "# Initialize an empty dictionary to group metrics by subsets (like '3com', '5com', etc.)\n",
    "grouped_metrics = {}\n",
    "\n",
    "# Loop through each metric CSV file found\n",
    "for file in metric_files:\n",
    "    filename = os.path.basename(file)  # Extract the filename from full path\n",
    "    \n",
    "    # Extract subset key from filename by splitting on \"com\" and adding it back, e.g., '3com', '7com'\n",
    "    subset_key = filename.split(\"com\")[0] + \"com\"\n",
    "    \n",
    "    # Detect the file's encoding to ensure proper CSV reading (handles various encodings)\n",
    "    encoding = detect_encoding(file)\n",
    "    \n",
    "    # Read the CSV file into a DataFrame using the detected encoding\n",
    "    df = pd.read_csv(file, encoding=encoding)\n",
    "    \n",
    "    # Compute the mean of all numeric columns to get average metric values for this file/fold\n",
    "    avg_metrics = df.mean(numeric_only=True)\n",
    "    \n",
    "    # Add a column 'Combination' to track which file this average comes from\n",
    "    avg_metrics[\"Combination\"] = filename\n",
    "    \n",
    "    # If the subset_key is not yet in the dictionary, create an empty list for it\n",
    "    if subset_key not in grouped_metrics:\n",
    "        grouped_metrics[subset_key] = []\n",
    "    \n",
    "    # Append the average metrics Series for this file to the list of that subset group\n",
    "    grouped_metrics[subset_key].append(avg_metrics)\n",
    "\n",
    "# Initialize a list to store summary DataFrames for each subset group\n",
    "summary_dfs = []\n",
    "\n",
    "# Loop over each subset group and its list of average metric Series\n",
    "for subset_key, metrics_list in grouped_metrics.items():\n",
    "    # Convert the list of Series to a DataFrame where each row is one file's average metrics\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    # Compute the mean across all files for each metric, excluding the 'Combination' column\n",
    "    avg_summary = metrics_df.drop(columns=[\"Combination\"]).mean()\n",
    "    \n",
    "    # Add metadata columns for clarity\n",
    "    avg_summary[\"Subset\"] = subset_key  # Label the subset group (e.g., '3com')\n",
    "    avg_summary[\"Num_Combinations\"] = len(metrics_list)  # Number of files combined\n",
    "    \n",
    "    # Append the summarized Series to the summary_dfs list\n",
    "    summary_dfs.append(avg_summary)\n",
    "\n",
    "# Combine all subset summary Series into a single summary DataFrame\n",
    "summary_df = pd.DataFrame(summary_dfs)\n",
    "\n",
    "# Define the desired column order: put 'Subset' and 'Num_Combinations' first, then all other columns\n",
    "columns = [\"Subset\", \"Num_Combinations\"] + [col for col in summary_df.columns if col not in [\"Subset\", \"Num_Combinations\"]]\n",
    "summary_df = summary_df[columns]  # Reorder columns accordingly\n",
    "\n",
    "# Define the output file path for the combined summary CSV\n",
    "summary_path = os.path.join(metrics_dir, \"subset_average_metrics_summary.csv\")\n",
    "\n",
    "# Save the final summary DataFrame to a CSV without the index column\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "# Print a confirmation message indicating where the summary was saved\n",
    "print(f\"✅ Saved summary of average metrics per subset to: {summary_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where all metric CSV files are stored\n",
    "metrics_dir = \"/Users/tuanadurmayuksel/Desktop/Multi_Final\"\n",
    "\n",
    "# Use glob to find all CSV files starting with \"model_metrics_\" in the specified directory\n",
    "metric_files = glob(os.path.join(metrics_dir, \"model_metrics_*.csv\"))\n",
    "\n",
    "# Initialize a dictionary to group metrics by subset key (e.g., '3com', '7com')\n",
    "grouped_metrics = {}\n",
    "\n",
    "# Loop through each metric CSV file found\n",
    "for file in metric_files:\n",
    "    filename = os.path.basename(file)  # Extract filename from full file path\n",
    "    \n",
    "    # Derive the subset key by taking the part before 'com' and appending 'com'\n",
    "    # For example, from '3com' or '7com' in the filename\n",
    "    subset_key = filename.split(\"com\")[0] + \"com\"\n",
    "    \n",
    "    # Read the CSV file into a pandas DataFrame (assuming default encoding)\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Calculate the mean of all numeric columns for the current file (averaging folds or runs)\n",
    "    avg_metrics = df.mean(numeric_only=True)\n",
    "    \n",
    "    # Add a 'Combination' column to store the filename as an identifier\n",
    "    avg_metrics[\"Combination\"] = filename\n",
    "    \n",
    "    # Initialize the list for this subset key if it does not exist yet\n",
    "    if subset_key not in grouped_metrics:\n",
    "        grouped_metrics[subset_key] = []\n",
    "    \n",
    "    # Append the average metrics (as a Series) for this file into the group list\n",
    "    grouped_metrics[subset_key].append(avg_metrics)\n",
    "\n",
    "# Create a list to store summary dictionaries for each subset\n",
    "summary_rows = []\n",
    "\n",
    "# For each subset group and its collected average metrics\n",
    "for subset_key, metrics_list in grouped_metrics.items():\n",
    "    # Convert the list of Series objects into a DataFrame for easier aggregation\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    # Start building a summary row with the subset name and number of files combined\n",
    "    row = {\"Subset\": subset_key, \"Num_Combinations\": len(metrics_list)}\n",
    "    \n",
    "    # For each metric column in the DataFrame\n",
    "    for metric in metrics_df.columns:\n",
    "        # Skip the 'Combination' column since it’s not a metric to aggregate\n",
    "        if metric == \"Combination\":\n",
    "            continue\n",
    "        \n",
    "        # Calculate the mean of this metric across all files in the subset and store it\n",
    "        row[f\"{metric}_mean\"] = metrics_df[metric].mean()\n",
    "        \n",
    "        # Calculate the standard deviation of this metric and store it\n",
    "        row[f\"{metric}_std\"] = metrics_df[metric].std()\n",
    "    \n",
    "    # Append the summary row dictionary to the list\n",
    "    summary_rows.append(row)\n",
    "\n",
    "# Convert the list of summary dictionaries to a DataFrame for saving\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Define the full path for the output CSV summary file\n",
    "summary_path = os.path.join(metrics_dir, \"subset_average_metrics_summary1.csv\")\n",
    "\n",
    "# Save the summary DataFrame to a CSV file without the index column\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "# Print confirmation message with the path where the summary file is saved\n",
    "print(f\"✅ Saved summary with mean & std metrics per subset to: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file containing subset average metrics into a DataFrame\n",
    "csv_path = \"/Users/tuanadurmayuksel/Desktop/Multi_Final/subset_average_metrics_summary.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Define the metric columns to plot and their prettier labels for display on the radar plot\n",
    "metrics_cols = ['Accuracy', 'AUC', 'F1_Micro', 'F1_Macro', 'Precision', 'Recall', 'Hamming_Loss']\n",
    "pretty_labels = ['Accuracy', 'AUC', 'F1 Micro', 'F1 Macro', 'Precision', 'Recall', 'Hamming Loss']\n",
    "\n",
    "# Calculate angles for radar plot axes; one angle per metric, evenly spaced around the circle\n",
    "num_vars = len(metrics_cols)\n",
    "angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "angles += angles[:1]  # Append first angle at the end to close the radar plot loop\n",
    "\n",
    "# Mapping from subset keys (matching 'Subset' values in df) to readable class size labels\n",
    "subset_to_class_size = {\n",
    "    'model_metrics_20com': '20 class size',\n",
    "    'model_metrics_15com': '15 class size',\n",
    "    'model_metrics_7com':  '7 class size',\n",
    "    'model_metrics_3com':  '3 class size'\n",
    "}\n",
    "\n",
    "# Define distinct colors for each subset group for the radar plot lines and fills\n",
    "subset_colors = {\n",
    "    'model_metrics_20com': '#FF8C00',  # dark orange\n",
    "    'model_metrics_15com': '#4169E1',  # royal blue\n",
    "    'model_metrics_7com':  '#DC143C',  # crimson\n",
    "    'model_metrics_3com':  '#228B22'   # forest green\n",
    "}\n",
    "\n",
    "# Define the order in which subsets will be plotted and displayed\n",
    "ordered_subsets = [\n",
    "    'model_metrics_20com',\n",
    "    'model_metrics_15com',\n",
    "    'model_metrics_7com',\n",
    "    'model_metrics_3com'\n",
    "]\n",
    "\n",
    "\n",
    "# === Create the radar plot figure with polar coordinates ===\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Loop over each subset to plot its average metric values on the radar\n",
    "for subset_name in ordered_subsets:\n",
    "    # Extract data rows for current subset\n",
    "    group = df[df['Subset'] == subset_name]\n",
    "    if group.empty:\n",
    "        continue  # Skip if no data for this subset\n",
    "    \n",
    "    # Compute mean metric values for the subset and close the loop for radar plot\n",
    "    values = group[metrics_cols].mean().values.tolist()\n",
    "    values += values[:1]  # close the radar polygon\n",
    "    \n",
    "    # Select color and label for this subset\n",
    "    color = subset_colors[subset_name]\n",
    "    label = subset_to_class_size[subset_name]\n",
    "    \n",
    "    # Plot the radar line and fill with transparency for visual effect\n",
    "    ax.plot(angles, values, color=color, linewidth=2.5, label=label)\n",
    "    ax.fill(angles, values, color=color, alpha=0.25)\n",
    "\n",
    "# Set the angle grid labels with pretty metric names, larger font for readability\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), pretty_labels, fontsize=30, fontweight='semibold', color=\"black\")\n",
    "\n",
    "# Set radial axis ticks from 0 to 1, labeled with 2 decimals\n",
    "radial_ticks = np.linspace(0, 1, 6)\n",
    "ax.set_yticks(radial_ticks)\n",
    "ax.set_yticklabels([f\"{x:.2f}\" for x in radial_ticks], fontsize=20, color='black')\n",
    "\n",
    "# Style radial grid lines with dashed black lines\n",
    "ax.yaxis.grid(True, color='black', linestyle='--', alpha=0.7, linewidth=1)\n",
    "\n",
    "# Fix the radial axis limits from 0 to 1 for all metrics\n",
    "ax.set_rlim(0, 1)\n",
    "\n",
    "# Rotate the plot so the first metric is at the top\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "\n",
    "# Set plot direction clockwise for more natural reading order\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Hide the circular border line around the radar plot\n",
    "ax.spines['polar'].set_visible(False)\n",
    "\n",
    "# Set the background color of the radar plot to white\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Add a legend outside the plot area, titled and sized for clarity\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.19), title='Class Sizes', fontsize=21, title_fontsize=22)\n",
    "\n",
    "# Adjust layout so nothing overlaps or is cut off\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the radar plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually provided improved metrics data for different class-size subsets\n",
    "data = {\n",
    "    'Subset': ['model_metrics_20com', 'model_metrics_7com', 'model_metrics_15com', 'model_metrics_3com'],\n",
    "    'Accuracy_mean': [0.0252, 0.2102, 0.0350, 0.4130],\n",
    "    'Accuracy_std': [0, 0.2321, 0.0058, 0.0823],\n",
    "    'AUC_mean': [0.5017, 0.5026, 0.5050, 0.5399],\n",
    "    'AUC_std': [0, 0.0007, 0.0006, 0.0344],\n",
    "    'F1_Micro_mean': [0.0648, 0.3369, 0.0750, 0.5616],\n",
    "    'F1_Micro_std': [0, 0.1976, 0.0184, 0.0444],\n",
    "    'F1_Macro_mean': [0.0188, 0.0887, 0.0220, 0.3577],\n",
    "    'F1_Macro_std': [0, 0.0199, 0.0029, 0.0513],\n",
    "    'Hamming_Loss_mean': [0.1166, 0.2099, 0.1100, 0.3106],\n",
    "    'Hamming_Loss_std': [0, 0.0605, 0.0124, 0.0437],\n",
    "    'Precision_mean': [0.4921, 0.5609, 0.5100, 0.6132],\n",
    "    'Precision_std': [0, 0.0736, 0.0102, 0.0507],\n",
    "    'Recall_mean': [0.0344, 0.2627, 0.0420, 0.5219],\n",
    "    'Recall_std': [0, 0.2081, 0.0103, 0.0523],\n",
    "}\n",
    "\n",
    "# Create DataFrame from manual data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract numerical class size from 'Subset' column and sort DataFrame ascending by class size\n",
    "df['Class_Size'] = df['Subset'].str.extract(r'_(\\d+)com').astype(int)\n",
    "df = df.sort_values(by='Class_Size', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Metrics and their prettier names for x-axis labels\n",
    "metrics = ['Accuracy', 'AUC', 'F1_Micro', 'F1_Macro', 'Hamming_Loss', 'Precision', 'Recall']\n",
    "pretty_metrics = ['Accuracy', 'AUC', 'F1 Micro', 'F1 Macro', 'Hamming Loss', 'Precision', 'Recall']\n",
    "\n",
    "# Mapping subset keys to simpler class size labels for legend\n",
    "subset_rename = {\n",
    "    'model_metrics_20com': '20 class',\n",
    "    'model_metrics_15com': '15 class',\n",
    "    'model_metrics_7com': '7 class',\n",
    "    'model_metrics_3com': '3 class',\n",
    "}\n",
    "\n",
    "# Assign a distinct color for each class size subset\n",
    "subset_colors = {\n",
    "    'model_metrics_20com': '#FF8C00',  # Dark orange\n",
    "    'model_metrics_15com': '#4169E1',  # Royal blue\n",
    "    'model_metrics_7com': '#DC143C',   # Crimson red\n",
    "    'model_metrics_3com': '#228B22',   # Forest green\n",
    "}\n",
    "\n",
    "# X locations for groups of bars (one bar group per metric)\n",
    "x = np.arange(len(metrics))\n",
    "\n",
    "# Width of each bar within a group (each subset will be offset horizontally)\n",
    "width = 0.18\n",
    "\n",
    "# Create the figure and axis for the bar plot with a wide layout\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Iterate over each subset row to plot bars with error bars\n",
    "for i, row in df.iterrows():\n",
    "    subset = row['Subset']\n",
    "    # Extract mean values for metrics and their std deviations\n",
    "    means = row[[m + '_mean' for m in metrics]].values.astype(float)\n",
    "    stds = row[[m + '_std' for m in metrics]].values.astype(float)\n",
    "\n",
    "    # Use std dev for error bars but ignore zero std by replacing them with NaN (no error bar)\n",
    "    error_bars = [std if std > 0 else np.nan for std in stds]\n",
    "\n",
    "    # Plot bars, horizontally offset by index to avoid overlap, with error bars and caps\n",
    "    ax.bar(x + i * width, means, width,\n",
    "           yerr=error_bars,\n",
    "           label=subset_rename.get(subset, subset),  # use readable label if available\n",
    "           color=subset_colors.get(subset, 'gray'),  # default color fallback\n",
    "           capsize=5,\n",
    "           edgecolor='black')\n",
    "\n",
    "# Set x-axis tick labels at center of grouped bars, with font size and rotation for readability\n",
    "ax.set_xticks(x + width * (len(df) - 1) / 2)\n",
    "ax.set_xticklabels(pretty_metrics, fontsize=30, fontweight='bold', rotation=25)\n",
    "\n",
    "# Configure y-axis limits and ticks from 0 to 1.0 with labels\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.set_yticks(np.linspace(0, 1, 11))\n",
    "ax.set_yticklabels([f\"{x:.1f}\" for x in np.linspace(0, 1, 11)], fontsize=30)\n",
    "\n",
    "# Axis labels for clarity\n",
    "ax.set_ylabel('Metric Values', fontsize=25)\n",
    "ax.set_xlabel('Metrics', fontsize=25)\n",
    "\n",
    "# Add legend for class sizes with title and font sizes\n",
    "ax.legend(title='Class Size', fontsize=25, title_fontsize=25)\n",
    "\n",
    "# Adjust layout to prevent overlap and tight spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate importance by Frequency and Biomarker by averaging over all sources\n",
    "agg_df = feature_df.groupby(['Frequency', 'Biomarker'])['importance'].mean().reset_index()\n",
    "\n",
    "# Pivot the data to have Biomarkers as rows and Frequency bands as columns\n",
    "# Note: column names should match exactly, so use proper capitalization\n",
    "heatmap_data = agg_df.pivot(index='Biomarker', columns='Frequency', values='importance')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Draw heatmap with annotations, using 'viridis' color map\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".3f\", cmap='viridis')\n",
    "\n",
    "plt.title('Biomarker x Frequency Importance Heatmap (Averaged over Sources)')\n",
    "plt.ylabel('Biomarker')\n",
    "plt.xlabel('Frequency Band')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate importance by frequency and biomarker, averaging over all sources\n",
    "agg_df = feature_df.groupby(['frequency', 'biomarker'])['importance'].mean().reset_index()\n",
    "\n",
    "# Pivot the DataFrame to create a matrix for the heatmap:\n",
    "# rows = biomarkers, columns = frequency bands, values = average importance scores\n",
    "heatmap_data = agg_df.pivot(index='biomarker', columns='frequency', values='importance')\n",
    "\n",
    "# Check if all importance values are zero (no meaningful data to plot)\n",
    "if np.max(heatmap_data.values) == 0:\n",
    "    print(\"All coefficient values are zero! Cannot plot meaningful heatmap.\")\n",
    "else:\n",
    "    # Normalize the importance values by dividing by the max value,\n",
    "    # to keep the color scale consistent and between 0-1\n",
    "    heatmap_data_norm = heatmap_data / np.max(heatmap_data.values)\n",
    "\n",
    "    # Clean up frequency column names by stripping any leading/trailing whitespace\n",
    "    heatmap_data_norm.columns = heatmap_data_norm.columns.str.strip()\n",
    "\n",
    "    # Clean up biomarker index names by stripping whitespace as well\n",
    "    heatmap_data_norm.index = heatmap_data_norm.index.str.strip()\n",
    "\n",
    "    # Set the figure size for better visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create the heatmap with seaborn\n",
    "    ax = sns.heatmap(\n",
    "        heatmap_data_norm,\n",
    "        cmap=\"YlGnBu\",            # Color map for a visually pleasant gradient\n",
    "        cbar_kws={'aspect': 35},  # Colorbar appearance settings (aspect ratio)\n",
    "        annot=True,               # Annotate cells with numeric values\n",
    "        fmt=\".3f\",                # Format numbers with 3 decimal places\n",
    "        annot_kws={\"size\": 20},   # Font size for annotations\n",
    "        linecolor='black',        # Color for grid lines between cells\n",
    "        linewidth=1               # Width of grid lines\n",
    "    )\n",
    "\n",
    "    # Set axis labels and font sizes\n",
    "    plt.xlabel(\"Frequency Band\", fontsize=18)\n",
    "    plt.ylabel(\"\", fontsize=18)  # Leaving y-label empty to use custom text instead\n",
    "\n",
    "    # Customize tick labels font size, rotation, and weight for readability\n",
    "    plt.xticks(fontsize=16, rotation=25, fontweight='bold')\n",
    "    plt.yticks(fontsize=16, rotation=0, fontweight='bold')\n",
    "\n",
    "    # Remove left spine (left vertical border line) for a cleaner look\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "    # Add a custom y-axis label \"Biomarker\" with specific position and rotation\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "    ax.text(\n",
    "        x=-0.10, y=0.40, s=\"Biomarker\",\n",
    "        fontsize=18, rotation=90,\n",
    "        ha='center', va='bottom',\n",
    "        transform=ax.transAxes\n",
    "    )\n",
    "\n",
    "    # Access the colorbar and set its font size and label\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    cbar.set_label('Normalized Importance', fontsize=20)\n",
    "\n",
    "    # Adjust layout to prevent clipping of labels and titles\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define disorder labels for rows and columns of the co-occurrence matrix\n",
    "labels = [\n",
    "    \"ADHD-C\", \"ADHD-H\", \"ADHD-I\", \"ADHD-Other\", \"Anxiety\", \"ASD\", \"CommDis\",\n",
    "    \"Depression\", \"Impulse\", \"Elimination\", \"Healthy\", \"ID\", \"OCD\", \"OCD-Other\",\n",
    "    \"ODD\", \"SLD-Math\", \"SLD-Read\", \"SLD-Write\", \"Tic\", \"Trauma-Stress\"\n",
    "]\n",
    "# Co-occurrence matrix where each entry represents the proportion of co-occurrence between disorders\n",
    "co_occurrence_data = [\n",
    "    [1.00, 0.11, 0.38, 0.12, 0.00, 0.13, 0.02, 0.04, 0.02, 0.08, 0.17, 0.05, 0.02, 0.04, 0.23, 0.00, 0.00, 0.02, 0.07, 0.01],\n",
    "    [0.11, 1.00, 0.12, 0.04, 0.00, 0.03, 0.04, 0.04, 0.03, 0.04, 0.03, 0.04, 0.03, 0.04, 0.11, 0.05, 0.04, 0.03, 0.06, 0.01],\n",
    "    [0.38, 0.12, 1.00, 0.14, 0.01, 0.03, 0.04, 0.04, 0.04, 0.05, 0.19, 0.04, 0.04, 0.04, 0.11, 0.08, 0.05, 0.05, 0.00, 0.03],\n",
    "    [0.12, 0.04, 0.14, 1.00, 0.00, 0.04, 0.03, 0.03, 0.03, 0.04, 0.06, 0.03, 0.04, 0.03, 0.09, 0.04, 0.04, 0.03, 0.03, 0.03],\n",
    "    [0.00, 0.00, 0.01, 0.00, 1.00, 0.03, 0.03, 0.01, 0.02, 0.03, 0.22, 0.04, 0.10, 0.03, 0.04, 0.12, 0.08, 0.04, 0.02, 0.07],\n",
    "    [0.13, 0.03, 0.03, 0.04, 0.03, 1.00, 0.01, 0.04, 0.03, 0.04, 0.12, 0.06, 0.10, 0.04, 0.02, 0.04, 0.04, 0.02, 0.06, 0.04],\n",
    "    [0.02, 0.03, 0.04, 0.03, 0.03, 0.01, 1.00, 0.07, 0.03, 0.03, 0.13, 0.01, 0.03, 0.02, 0.01, 0.17, 0.16, 0.12, 0.03, 0.00],\n",
    "    [0.04, 0.04, 0.04, 0.02, 0.01, 0.04, 0.07, 1.00, 0.04, 0.03, 0.10, 0.05, 0.08, 0.05, 0.08, 0.05, 0.09, 0.05, 0.01, 0.07],\n",
    "    [0.02, 0.03, 0.04, 0.03, 0.02, 0.03, 0.03, 0.04, 1.00, 0.03, 0.04, 0.02, 0.03, 0.02, 0.11, 0.02, 0.03, 0.04, 0.00, 0.02],\n",
    "    [0.08, 0.04, 0.05, 0.04, 0.03, 0.04, 0.03, 0.03, 0.03, 1.00, 0.10, 0.02, 0.01, 0.01, 0.11, 0.02, 0.02, 0.03, 0.02, 0.01],\n",
    "    [0.17, 0.03, 0.19, 0.06, 0.22, 0.12, 0.13, 0.10, 0.04, 0.10, 1.00, 0.06, 0.06, 0.04, 0.09, 0.09, 0.14, 0.08, 0.09, 0.06],\n",
    "    [0.05, 0.04, 0.04, 0.03, 0.04, 0.06, 0.01, 0.05, 0.02, 0.02, 0.06, 1.00, 0.03, 0.03, 0.06, 0.03, 0.03, 0.06, 0.02, 0.01],\n",
    "    [0.02, 0.03, 0.04, 0.04, 0.10, 0.10, 0.03, 0.08, 0.03, 0.01, 0.06, 0.03, 1.00, 0.06, 0.03, 0.02, 0.04, 0.04, 0.11, 0.03],\n",
    "    [0.04, 0.04, 0.04, 0.03, 0.03, 0.04, 0.02, 0.05, 0.02, 0.01, 0.04, 0.03, 0.06, 1.00, 0.04, 0.03, 0.04, 0.04, 0.01, 0.03],\n",
    "    [0.23, 0.11, 0.11, 0.09, 0.04, 0.02, 0.01, 0.08, 0.11, 0.11, 0.09, 0.06, 0.03, 0.04, 1.00, 0.11, 0.03, 0.03, 0.03, 0.03],\n",
    "    [0.00, 0.05, 0.08, 0.04, 0.12, 0.04, 0.17, 0.05, 0.02, 0.02, 0.09, 0.03, 0.02, 0.03, 0.11, 1.00, 0.23, 0.30, 0.02, 0.04],\n",
    "    [0.00, 0.04, 0.05, 0.04, 0.08, 0.04, 0.16, 0.09, 0.03, 0.02, 0.14, 0.03, 0.04, 0.04, 0.03, 0.23, 1.00, 0.26, 0.02, 0.03],\n",
    "    [0.02, 0.03, 0.05, 0.03, 0.04, 0.02, 0.12, 0.05, 0.04, 0.03, 0.08, 0.06, 0.04, 0.04, 0.03, 0.30, 0.26, 1.00, 0.02, 0.03],\n",
    "    [0.07, 0.06, 0.00, 0.03, 0.02, 0.06, 0.03, 0.01, 0.00, 0.02, 0.09, 0.02, 0.11, 0.01, 0.03, 0.02, 0.02, 0.02, 1.00, 0.04],\n",
    "    [0.01, 0.01, 0.03, 0.03, 0.07, 0.04, 0.00, 0.07, 0.02, 0.01, 0.06, 0.01, 0.03, 0.03, 0.03, 0.04, 0.03, 0.03, 0.04, 1.00]\n",
    "]\n",
    "\n",
    "# Convert the raw data into a pandas DataFrame for easier manipulation and visualization\n",
    "co_matrix = pd.DataFrame(co_occurrence_data, index=labels, columns=labels)\n",
    "\n",
    "# Set up the plot size for readability\n",
    "plt.figure(figsize=(13, 11))\n",
    "\n",
    "# Create a heatmap to visualize the co-occurrence matrix\n",
    "ax = sns.heatmap(\n",
    "    co_matrix,\n",
    "    fmt=\".1f\",             # Format values with one decimal place\n",
    "    cmap=\"YlGnBu\",         # Use a yellow-green-blue color palette\n",
    "    square=True,           # Make each cell square-shaped for uniformity\n",
    "    cbar_kws={'label': 'Proportion'},  # Label for the colorbar\n",
    "    linewidths=0.8,        # Width of lines between cells\n",
    "    linecolor='gray',      # Color of lines between cells\n",
    ")\n",
    "\n",
    "# Customize tick labels: font size, rotation, and alignment for clarity\n",
    "plt.xticks(fontsize=23, rotation=45, ha='right')  # Rotate x-axis labels diagonally\n",
    "plt.yticks(fontsize=23)\n",
    "\n",
    "# Add labels for x and y axes with larger, bold fonts\n",
    "plt.xlabel(\"Disorders\", fontsize=20, weight='bold')\n",
    "plt.ylabel(\"Co-occurrence\", fontsize=20, weight='bold')\n",
    "\n",
    "# Customize the colorbar label and tick labels font sizes\n",
    "colorbar = ax.collections[0].colorbar\n",
    "colorbar.set_label('Proportion', fontsize=20, weight='bold')\n",
    "colorbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "# Add a title to the heatmap with an appropriate font size\n",
    "plt.title(\"Disorder Co-occurrence Matrix\", fontsize=18)\n",
    "\n",
    "# Adjust layout to prevent label overlap or clipping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the final heatmap plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually entered SHAP importance values for different frequency bands and biomarkers\n",
    "data = {\n",
    "    'Alpha':         [0.41, 0.10, 0.18, 0.23],\n",
    "    'Beta':          [1.00, 0.17, 0.22, 0.26],\n",
    "    'Delta':         [0.57, 0.25, 0.18, 0.10],\n",
    "    'Gamma':         [0.91, 0.18, 0.36, 0.29],\n",
    "    'Theta':         [0.53, 0.28, 0.14, 0.19],\n",
    "}\n",
    "index = ['AbsolutePower', 'DFA', 'RelativePower', 'fEI']\n",
    "\n",
    "# Create DataFrame with biomarkers as rows, frequency bands as columns\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "# Normalize the data by dividing by the maximum value in the entire DataFrame\n",
    "df_norm = df / df.values.max()\n",
    "\n",
    "# Rename some row indices for brevity\n",
    "df_norm.columns = df_norm.columns.str.strip()\n",
    "df_norm = df_norm.rename(index={\n",
    "    'RelativePower': 'RP',\n",
    "    'AbsolutePower': 'AP'\n",
    "})\n",
    "\n",
    "# Plotting the heatmap with customized appearance\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.heatmap(\n",
    "    df_norm,\n",
    "    cmap=\"YlGnBu\",               # Color palette: yellow-green-blue\n",
    "    cbar_kws={'aspect': 35},     # Aspect ratio of the color bar\n",
    "    annot=True,                  # Show values on heatmap cells\n",
    "    fmt=\".2f\",                   # Format annotation to 2 decimal places\n",
    "    annot_kws={\"size\": 25},      # Font size for annotations\n",
    "    linecolor='black',           # Color of grid lines between cells\n",
    "    linewidth=1                  # Width of grid lines\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Frequency Band\", fontsize=25)\n",
    "plt.ylabel(\"\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=25, rotation=25, fontweight='bold')  # Rotate and format x-axis labels\n",
    "plt.yticks(fontsize=20, rotation=0, fontweight='bold')   # Format y-axis labels\n",
    "\n",
    "# Remove left spine (the vertical border line on the y-axis)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "# Add a vertical \"Biomarker\" label to the left side of the heatmap\n",
    "ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "ax.text(\n",
    "    x=-0.11, y=0.25, s=\"Biomarker\",\n",
    "    fontsize=25, rotation=90,\n",
    "    ha='center', va='bottom',\n",
    "    transform=ax.transAxes\n",
    ")\n",
    "\n",
    "# Format color bar ticks and label font size\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label('Normalized SHAP Importance', fontsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
